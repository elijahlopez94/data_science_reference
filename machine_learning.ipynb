{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Data Science Toolkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import category_encoders as ce\n",
    "\n",
    "# Machine Learning Preprocessing and Scoring Metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score, RepeatedKFold, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, mean_squared_error, r2_score, explained_variance_score, roc_curve, auc\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Machine Learning Algorithms\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using one-hot encoding:\n",
    "X = pd.get_dummies(X, columns=[''], drop_first=True, dtype=int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "# Isolate categorical columns\n",
    "X_train_categorical = X_train_fill_na.select_dtypes(exclude=[\"int64\", \"float64\"]).copy()\n",
    "X_train_categorical\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "ohe.fit(X_train_categorical)\n",
    "X_train_ohe = pd.DataFrame(\n",
    "    ohe.transform(X_train_categorical),\n",
    "    # index is important to ensure we can concatenate with other columns\n",
    "    index=X_train_categorical.index,\n",
    "    # we are dummying multiple columns at once, so stack the names\n",
    "    columns=np.hstack(ohe.categories_)\n",
    ")\n",
    "X_train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder - Changes Target column values to be in range [0, n)\n",
    "# Instantiate the encoder\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformer\n",
    "# Instantiate Column Transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['category']),\n",
    "    ('name_2', transformer(), ['columns_to_apply_to'])\n",
    "], remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1, figsize = (3,3), dpi=300)\n",
    "tree.plot_tree(model,\n",
    "               feature_names = X.columns.tolist(), \n",
    "               class_names=np.unique(y).astype('str').tolist(),\n",
    "               filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regression_models(X_train, y_train):\n",
    "    # Adjustments\n",
    "    CV = 10\n",
    "    SCORING = 'neg_mean_squared_error' \n",
    "    \n",
    "    # Define the models to be tested\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42),\n",
    "        \"Support Vector Regressor\": SVR()\n",
    "    }\n",
    "    \n",
    "    # Initialize results dictionary to store metrics for each model\n",
    "    results = {\n",
    "        \"Model\": [],\n",
    "        \"Mean Squared Error\": [],\n",
    "        \"Spread (std)\": [],\n",
    "        \"Train Time (s)\": [],\n",
    "        \"Memory Usage (MB)\": []\n",
    "    }\n",
    "    \n",
    "    # Perform model evaluation for each model\n",
    "    for model_name, model in models.items():\n",
    "        # Measure training time\n",
    "        start_train_time = time.time()\n",
    "\n",
    "        # Perform k-fold cross-validation to evaluate the model on the training data\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=CV, scoring=SCORING)\n",
    "\n",
    "        end_train_time = time.time()\n",
    "        train_time = end_train_time - start_train_time\n",
    "\n",
    "        # Measure memory usage (in MB)\n",
    "        memory_usage = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "        \n",
    "        # Convert MSE scores to positive values\n",
    "        mse_scores = -cv_scores\n",
    "\n",
    "        # Store the metrics in the results dictionary\n",
    "        results[\"Model\"].append(model_name)\n",
    "        results[\"Mean Squared Error\"].append(round(np.mean(mse_scores), 4))\n",
    "        results[\"Spread (std)\"].append(round(np.std(mse_scores), 4))\n",
    "        results[\"Train Time (s)\"].append(round(train_time, 4))\n",
    "        results[\"Memory Usage (MB)\"].append(round(memory_usage, 0))\n",
    "        \n",
    "    # Create a DataFrame to display the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print the results\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification_models(X_train, y_train):\n",
    "    # Adjustments\n",
    "    CV = 10\n",
    "    SCORING = 'accuracy'\n",
    "    \n",
    "    \n",
    "    # Define the models to be tested\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(random_state=42),\n",
    "        \"Support Vector Machine\": SVC(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Initialize results dictionary to store metrics for each model\n",
    "    results = {\n",
    "        \"Model\": [],\n",
    "        \"Accuracy (%)\": [],\n",
    "        \"Spread (std)\": [],\n",
    "        \"Train Time (s)\": [],\n",
    "        \"Memory Usage (MB)\": []\n",
    "    }\n",
    "    \n",
    "    # Perform model evaluation for each model\n",
    "    for model_name, model in models.items():\n",
    "        # Measure training time\n",
    "        start_train_time = time.time()\n",
    "\n",
    "        # Perform k-fold cross-validation to evaluate the model on the training data\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=CV, scoring=SCORING)\n",
    "\n",
    "        end_train_time = time.time()\n",
    "        train_time = end_train_time - start_train_time\n",
    "\n",
    "        # Measure memory usage (in MB)\n",
    "        memory_usage = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "        \n",
    "        # Store the metrics in the results dictionary\n",
    "        results[\"Model\"].append(model_name)\n",
    "        results[\"Accuracy (%)\"].append(round(np.mean(cv_scores) * 100, 2))\n",
    "        results[\"Spread (std)\"].append(round(np.std(cv_scores), 4))\n",
    "        results[\"Train Time (s)\"].append(round(train_time, 4))\n",
    "        results[\"Memory Usage (MB)\"].append(round(memory_usage, 0))\n",
    "        \n",
    "    # Create a DataFrame to display the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print the results\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagged_tree = BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=5), n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances + Visualization\n",
    "model = ''\n",
    "\n",
    "features = model.feature_importances_\n",
    "\n",
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n",
    "\n",
    "plot_feature_importances(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TPOT\n",
    "# Construct and fit TPOT classifier\n",
    "start_time = time.time()\n",
    "tpot = TPOTClassifier(generations=5, population_size=10, random_state=42, n_jobs=-1, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Results\n",
    "print('TPOT classifier finished in %s seconds' % (end_time - start_time)) \n",
    "print('Best pipeline test accuracy: %.3f' % tpot.score(X_test, y_test))\n",
    "\n",
    "# See best performing model and hyperparameters\n",
    "best_model = tpot.fitted_pipeline_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "clf = ''\n",
    "mean_clf_cv = cross_val_score(clf, X_train, y_train).mean()\n",
    "print(f\"Mean Cross Validation Score for Random Forest Classifier: {mean_clf_cv :.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "# Set hyperparamter grid\n",
    "param_grid = {\n",
    "    'hyperparameter_1': ['name_1', 'name_2'],\n",
    "    'hyperparameter_2': [None, 1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Fit to model\n",
    "gs = GridSearchCV(clf, param_grid, cv=3, return_train_score=True)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate training/testing score. Note train/test time also available\n",
    "gs_train_score = gs.cv_results_['mean_train_score'].mean()\n",
    "gs_test_score = gs.cv_results_['mean_test_score'].mean()\n",
    "gs_best_params = gs.best_params_\n",
    "\n",
    "print(f\"Mean Training Score: {gs_train_score :.2%}\")\n",
    "print(f\"Mean Test Score: {gs_test_score :.2%}\")\n",
    "print(f\"Best Parameter Combination Found During Grid Search: {gs_best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines with GridSearch\n",
    "# Create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing_step_1', step_1_action),\n",
    "    ('preprocessing_step_2', step_2_action),\n",
    "    ('clf', clf())\n",
    "])\n",
    "\n",
    "# Utilize GridSearch, note the use of 'model__' followed by the hyperparamter\n",
    "param_grid = [{'model__max_depth': [None, 2, 6, 10], \n",
    "         'model__min_samples_split': [5, 10]}]\n",
    "\n",
    "# Create the grid, with \"pipe\" as the estimator\n",
    "gridsearch = GridSearchCV(estimator=pipe, \n",
    "                          param_grid=param_grid, \n",
    "                          scoring='accuracy', \n",
    "                          cv=5)\n",
    "\n",
    "# Fit pipeline\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Print accuracy\n",
    "gridsearch.score(X_test, y_test)\n",
    "\n",
    "\"\"\"\n",
    "If not using grid search can also use:\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex pipeline\n",
    "\n",
    "def preprocess_data_with_pipeline(X):\n",
    "    \n",
    "    ### Encoding categorical data ###\n",
    "    original_features_encoded = ColumnTransformer(transformers=[\n",
    "        (\"ohe\", OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\"), [\"category\"])\n",
    "    ], remainder=\"passthrough\")\n",
    "    \n",
    "    ### Feature engineering ###\n",
    "    def is_odd(data):\n",
    "        \"\"\"\n",
    "        Helper function that returns 1 if odd, 0 if even\n",
    "        \"\"\"\n",
    "        return data % 2\n",
    "\n",
    "    feature_eng = ColumnTransformer(transformers=[\n",
    "        (\"add_number_odd\", FunctionTransformer(is_odd), [\"number\"])\n",
    "    ], remainder=\"drop\")\n",
    "  \n",
    "    ### Combine encoded and engineered features ###\n",
    "    feature_union = FeatureUnion(transformer_list=[\n",
    "        (\"encoded_features\", original_features_encoded),\n",
    "        (\"engineered_features\", feature_eng)\n",
    "    ])\n",
    "    \n",
    "    ### Pipeline (including scaling) ###\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"feature_union\", feature_union),\n",
    "        (\"scale\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    transformed_data = pipe.fit_transform(X)\n",
    "    \n",
    "    ### Re-apply labels (optional step for readability) ###\n",
    "    encoder = original_features_encoded.named_transformers_[\"ohe\"]\n",
    "    category_labels = encoder.categories_[0]\n",
    "    all_cols = list(category_labels) + [\"number\", \"number_odd\"]\n",
    "    return pd.DataFrame(transformed_data, columns=all_cols, index=X.index), pipe\n",
    "    \n",
    "# Reset value of example_X\n",
    "example_X = example_data.drop(\"target\", axis=1)\n",
    "# Test out our new function\n",
    "result, pipe = preprocess_data_with_pipeline(example_X)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using autosklearn.classification\n",
    "import autosklearn.classification\n",
    "\n",
    "model = autosklearn.classification.AutoSklearnClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender Systems\n",
    "# Imports (Similar to sklearn but run different)\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Read in values as Surprise dataset \n",
    "reader = Reader(rating_scale=(0, 5))    #Customize to rating range\n",
    "data = Dataset.load_from_df(df, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "def clean_string(list_of_words):\n",
    "# Clean string of new line characters and punctuation then make lower case    \n",
    "    one_string = ''.join(list).replace('\\n', ' ')\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    words = one_string.translate(translator)\n",
    "    lower = words.lower()\n",
    "    return lower\n",
    "\n",
    "# Tokenize and remove 'stop words'\n",
    "tokenized_string = word_tokenize(cleaned_string)\n",
    "stop_words = stopwords.words('english')\n",
    "clean_tokens = [word for word in tokenized_string if word not in stop_words]\n",
    "\n",
    "# Lemmatizaation\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = lemmatizer.lemmatize(clean_tokens)\n",
    "\n",
    "# Vectorize\n",
    "def count_vectorize(lemmatized_tokens):\n",
    "    vector = {}\n",
    "    for word in lemmatized_tokens:\n",
    "        if word in vector.keys():\n",
    "            vector[word] += 1\n",
    "        else:\n",
    "            vector[word] = 1\n",
    "    return vector\n",
    "\n",
    "# Alternative vectorization:\n",
    "freqdist = FreqDist(lemmatized_tokens)\n",
    "most_common = freqdist.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning\n",
    "# Print Historical Summary of Training & Validation Accuracy by Epoch\n",
    "def display_historical_summaries(history):\n",
    "  \"\"\" Custom function to utilize model fitness history to visualize accuracy. \"\"\"\n",
    "  plt.plot(history.history[\"accuracy\"], label=\"training\")\n",
    "  plt.plot(history.history[\"val_accuracy\"], label=\"validation\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "display_historical_summaries(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasnfer Learning Example\n",
    "\n",
    "# Pull in source model\n",
    "output = vgg.layers[-1].output\n",
    "output = Flatten()(output)\n",
    "base_model = Model(vgg.input, output)\n",
    "\n",
    "# Freeze model and all internal layers\n",
    "base_model.trainable = False\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Visualize frozen layer architecture for base model\n",
    "# pd.set_option(\"max_colwidth\", -1)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in base_model.layers]\n",
    "pd.DataFrame(layers, columns=[\"Layer Type\", \"Layer Name\", \"Is Layer Trainable?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation to reduce chances of learning from noise (overfitting)\n",
    "\n",
    "ImageDataGenerator =  tf.keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "# Create image augmentation engine as generator-like object\n",
    "generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=5,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    ")\n",
    "\n",
    "# Fit training data to augmentation generator\n",
    "generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Accuracy and Loss by Epochs\n",
    "def plot_training_results(history):\n",
    "    \"\"\"\n",
    "    Visualize results of the model training using `matplotlib`.\n",
    "\n",
    "    The visualization will include charts for accuracy and loss,\n",
    "    on the training and as well as validation data sets.\n",
    "\n",
    "    INPUTS:\n",
    "        history(tf.keras.callbacks.History):\n",
    "            Contains data on how the model metrics changed\n",
    "            over the course of training.\n",
    "\n",
    "    OUTPUTS:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    # Get accuracy for training and validation sets\n",
    "    accuracy = history.history['accuracy']\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Get loss for training and validation sets\n",
    "    loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "\n",
    "    # Get range of epochs to produce common plotting range\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    # Instantiate plotting figure space\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    # Create training/validation accuracy subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    # Create training/validation loss subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Render visualization\n",
    "    plt.show()\n",
    "\n",
    "plot_training_results(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cohort_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
