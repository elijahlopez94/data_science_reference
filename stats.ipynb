{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Data Science Toolkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import category_encoders as ce\n",
    "\n",
    "# Inferential Statistical Tests\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from scipy.stats import chi2_contingency, ttest_ind, ttest_rel, f_oneway, pearsonr\n",
    "from scipy.stats import zscore, norm, binom, poisson\n",
    "from scipy.stats import kruskal\n",
    "from scikit_posthocs import posthoc_dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the required sample size\n",
    "def determine_sample_size(p0, p1, alpha=0.05, power=0.8):\n",
    "    \"\"\"Takes in:\n",
    "    p0: Current rate as float\n",
    "    p1: Desired rate (current rate +/- change) as float\n",
    "    alpha: Confidence level as float\n",
    "    power: Desired power level as float\n",
    "\n",
    "    Returns sample size required for given inputs\n",
    "    \"\"\"\n",
    "    effect_size = sm.stats.proportion_effectsize(p0,p1)\n",
    "    sample_size = sm.stats.NormalIndPower().solve_power(effect_size, alpha=alpha, power=power, ratio=1)\n",
    "\n",
    "    return print(f'Required sample size per group: {sample_size:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the z-scores for each value in normal_dist, standardizing\n",
    "# the data by subtracting the mean and dividing by the standard deviation.\n",
    "z_dist = [(x - np.mean(normal_dist)) / np.std(normal_dist)\n",
    "          for x in normal_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Confidence Interval of a Normally distributed sample\n",
    "sample_size = #\n",
    "sample = df.sample(n=sample_size)\n",
    "sample_mean = sample.mean()\n",
    "\n",
    "ci = stats.t.interval(\n",
    "    confidence=0.95,               # Confidence level\n",
    "    df=sample_size - 1,             # Degrees of freedom\n",
    "    loc=sample_mean,                # Sample mean\n",
    "    scale=sample.std() / np.sqrt(sample_size)  # Standard error calculated here\n",
    ")\n",
    "\n",
    "print(\"Confidence Interval:\", ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(sample_mean, h0_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Tailed T-Test\n",
    "\"\"\"\n",
    "# Default here is two-tailed t-test\n",
    "result = stats.ttest_ind(own, rent)\n",
    "print(result)\n",
    "pvalue = result.pvalue\n",
    "print(pvalue)\n",
    "pvalue < alpha \n",
    "\"\"\"\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(own, rent)\n",
    "\n",
    "# Use < for \"less than\" or > for \"greater than\" one tailed t-test\n",
    "# H1 < H0 so in this case use <\n",
    "\n",
    "one_tailed_p_value = p_value / 2 if t_stat < 0 else 1.0\n",
    "print(one_tailed_p_value)\n",
    "one_tailed_p_value < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA\n",
    "def perform_anova(df, group_col, value_col, alpha):\n",
    "    \"\"\"\n",
    "    Performs a one-way ANOVA test to compare means across groups.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.dfFrame) - The df with data/groups\n",
    "        group_col (str) - The column name representing the groups\n",
    "        value_col (str) - The column name representing the values to compare\n",
    "        alpha (float) - Confidence level\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the F-Statistic, P-Value, and interpretation.\n",
    "    \"\"\"\n",
    "    # Group the df by the specified group column\n",
    "    grouped = df.groupby(group_col)[value_col]\n",
    "    \n",
    "    # Extract values for each group into separate lists\n",
    "    grouped_values = [grouped.get_group(group).values for group in grouped.groups.keys()]\n",
    "    \n",
    "    # Perform ANOVA test\n",
    "    f_stat, p_value = f_oneway(*grouped_values)\n",
    "    \n",
    "    # Interpretation\n",
    "    result = {\n",
    "        \"F-Statistic\": f_stat,\n",
    "        \"P-Value\": p_value,\n",
    "        \"Significance\": \"Reject the null in favor of the alterantive hypothesis.\"\n",
    "        if p_value < 0.05 else \"Fail to reject the null hypothesis\"\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'S ~ C(E) + C(M) + X'\n",
    "lm = ols(formula, df).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness of Fit\n",
    "observed_values = counts.values\n",
    "result = stats.chisquare(observed_values, expected_values)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Result\n",
    "\n",
    "def plot_chi_squared_distribution(df, critical_percentile=0.95, x_range=(0, 30), num_points=500):\n",
    "    \"\"\"\n",
    "    Plots a Chi-square distribution PDF with a critical value line.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Degrees of freedom for the Chi-square distribution.\n",
    "    - critical_percentile: The percentile for the critical value (default is 0.95).\n",
    "    - x_range: The range for the x-axis (default is from 0 to 30).\n",
    "    - num_points: The number of points in the x range (default is 500).\n",
    "    \"\"\"\n",
    "    # Generate x values (Chi-square statistic range)\n",
    "    x = np.linspace(x_range[0], x_range[1], num_points)\n",
    "\n",
    "    # Calculate the corresponding y values (PDF of the Chi-square distribution)\n",
    "    y = stats.chi2.pdf(x, df)\n",
    "\n",
    "    # Calculate the critical value for the Chi-square distribution\n",
    "    critical_value = stats.chi2.ppf(critical_percentile, df)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, color='darkblue', label=r\"$\\chi^2$ distribution PDF\")\n",
    "    ax.axvline(critical_value, color='green', linestyle=\"--\", label=r\"critical $\\chi^2$\")\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax.set_xlabel(r\"$\\chi^2$ statistic\")\n",
    "    ax.set_ylabel(\"Probability Density\")\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_chi_squared_distribution(df=10)  # You can modify df and other parameters as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of Independence\n",
    "independence_table = pd.crosstab(col_1, col_2)\n",
    "chi2, pvalue, dof, ex = stats.chi2_contingency(independence_table)\n",
    "\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of Homogeneity\n",
    "\n",
    "# The goal is comparing the distributions of two population samples,\n",
    "# to understand whether their underlying populations follow the same distribution.\n",
    "homogeneity_table = pd.crosstab(col_1, col_2)\n",
    "\n",
    "chi2, p, dof, ex = stats.chi2_contingency(homogeneity_table)\n",
    "\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS\n",
    "# Have to have one column of constant values. If not present, use:\n",
    "model = sm.OLS(endog=y, exog=sm.add_constant(X))\n",
    "\n",
    "results = model.fit()\n",
    "results.summary()   # Display important information about the test\n",
    "\n",
    "# Visualize: Confidence interval based off t-distribution\n",
    "sm.graphics.plot_fit(results, \"height\")\n",
    "plt.show()\n",
    "\n",
    "# Linear Visualization:\n",
    "fig, ax = plt.subplots()\n",
    "df.plot.scatter(x=\"height\", y=\"weight\", label=\"Data points\", ax=ax)\n",
    "sm.graphics.abline_plot(model_results=results, label='Regression Line', ax=ax, color='red')\n",
    "ax.legend();\n",
    "\n",
    "# Linear with confidence interval using Seaborn\n",
    "sns.regplot(x=\"height\", y=\"weight\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If comparing Numeric and Categorical Data\n",
    "\n",
    "# Dependent variable ~ Independent variable\n",
    "# ~ Expresses relationship\n",
    "# C() indicates that the independent variable in this case is categorical\n",
    "\n",
    "formula = 'col_1 ~ C(col_2)'\n",
    "lm = ols(formula, df).fit()\n",
    "\n",
    "# ANOVA\n",
    "sm.stats.anova_lm(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial regression displays marginal contribution of each feature\n",
    "\"\"\"If this plot shows a linear relationship with a non-zero slope, \n",
    "that means that it is beneficial to add `weight` to the model, vs. having a model without `weight`\"\"\"\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "sm.graphics.plot_partregress_grid(results, exog_idx=['', ''], fig=fig)      # Can also use exog_inx=list(X.columns.values()) if using all columns\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain relationship between X and y\n",
    "results.rsquared\n",
    "\n",
    "# Always show params and pvalues to validate linear (or polynomial) models\n",
    "results.params\n",
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Residuals\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(data['mpg'], baseline_results.resid)\n",
    "ax.axhline(y=0, color='red')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('residuals');"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
