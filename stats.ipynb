{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Data Science Toolkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import category_encoders as ce\n",
    "\n",
    "# Inferential Statistical Tests\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from scipy.stats import chi2_contingency, ttest_ind, ttest_rel, f_oneway, pearsonr\n",
    "from scipy.stats import zscore, norm, binom, poisson\n",
    "from scipy.stats import kruskal\n",
    "from scikit_posthocs import posthoc_dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the required sample size\n",
    "def determine_sample_size(p0, p1, alpha=0.05, power=0.8):\n",
    "    \"\"\"Takes in:\n",
    "    p0: Current rate as float\n",
    "    p1: Desired rate (current rate +/- change) as float\n",
    "    alpha: Confidence level as float\n",
    "    power: Desired power level as float\n",
    "\n",
    "    Returns sample size required for given inputs\n",
    "    \"\"\"\n",
    "    effect_size = sm.stats.proportion_effectsize(p0,p1)\n",
    "    sample_size = sm.stats.NormalIndPower().solve_power(effect_size, alpha=alpha, power=power, ratio=1)\n",
    "\n",
    "    return print(f'Required sample size per group: {sample_size:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the z-scores for each value in normal_dist, standardizing\n",
    "# the data by subtracting the mean and dividing by the standard deviation.\n",
    "z_dist = [(x - np.mean(normal_dist)) / np.std(normal_dist)\n",
    "          for x in normal_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Confidence Interval of a Normally distributed sample\n",
    "sample_size = #\n",
    "sample = df.sample(n=sample_size)\n",
    "sample_mean = sample.mean()\n",
    "\n",
    "ci = stats.t.interval(\n",
    "    confidence=0.95,               # Confidence level\n",
    "    df=sample_size - 1,             # Degrees of freedom\n",
    "    loc=sample_mean,                # Sample mean\n",
    "    scale=sample.std() / np.sqrt(sample_size)  # Standard error calculated here\n",
    ")\n",
    "\n",
    "print(\"Confidence Interval:\", ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(sample_mean, h0_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Tailed T-Test\n",
    "\"\"\"\n",
    "# Default here is two-tailed t-test\n",
    "result = stats.ttest_ind(own, rent)\n",
    "print(result)\n",
    "pvalue = result.pvalue\n",
    "print(pvalue)\n",
    "pvalue < alpha \n",
    "\"\"\"\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(own, rent)\n",
    "\n",
    "# Use < for \"less than\" or > for \"greater than\" one tailed t-test\n",
    "# H1 < H0 so in this case use <\n",
    "\n",
    "one_tailed_p_value = p_value / 2 if t_stat < 0 else 1.0\n",
    "print(one_tailed_p_value)\n",
    "one_tailed_p_value < alpha"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
